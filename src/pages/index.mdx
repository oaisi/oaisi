---
layout: ../layouts/Layout.astro
---

<div class='calloutbox'>
Currently running:
- [**ARBOx applications open**](arbox): a two-week ML safety intensive running in beginning of July, applications open now until the 25th of May [Apply here](https://airtable.com/appjnmCupjy4cn0EG/pag53x1mwSivabJAq/form).
- **Technical Roundtables**: a weekly meeting on Monday evenings for researchers to share new developments in the field of technical AGI safety, and discuss over dinner. [Apply here](https://airtable.com/appPbXWANQ4eZYAKa/pag0h45iW7E7ue5r8/form).
- **Control reading group**: (currently full) following this [syllabus](https://docs.google.com/document/d/1dBlzu0xB-9KJumixzi-9AIZATyKq-U66HylioqXy4JI/preview). If you'd be interested to set up your own small AI safety-related reading group, please let us know with [this form](https://forms.gle/MpPYCWAEn32BZepb8), and we'd be excited to chat!
- [**Projects**](projects): work on an AI safety project in a group environment (pizza and project ideas provided!) every Thursday 5-9pm during term at the Computer Science department.

</div>

**Catastrophic risk from advanced artificial intelligence may be the defining
issue of our time.**

OAISI's role is to **support the AI safety community in Oxford**. You can find
out more about our mission [here](about).

If you're an AI safety researcher visiting Oxford, reach out to us
[here](mailto:rohan@oaisi.org). If you're based in Oxford and want to
reach out, email us [here](mailto:rohan@oaisi.org).

To get regular updates on what we're doing, sign up to our
[mailing list](http://eepurl.com/i1scNU).

Go to our [get in touch](getintouch) page to book 1-1 sessions with our
committee to chat about AI safety, OAISI, and how you can get involved.

<hr/>

Previous:

- [**ARBOx**](arbox) is our ML safety bootcamp, we will run the second iteration from the 30th of June till the 11th of July
- A series of [**introductory talks**](introtalks) with _Orshi Dobe_, _Suryansh Mehta_, and _Michael Aird_ at the beginning of October
- Our [**Strategy Fellowship**](strategy) ran in Michaelmas, where participants grew their understanding of AIS metastrategy.
- A [**symposium**](narratingaifutures) focused on communication, media, and advocacy in AI safety.
- An [**AI Safety Fellowship**](aisafetyfellowship) exploring the fundamentals of AI safety from technical and governance perspectives
