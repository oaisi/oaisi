---
layout: ../layouts/Layout.astro
---

{/* <div class='calloutbox'>


**Catastrophic risk from advanced artificial intelligence may be the defining
issue of our time.**

OAISI's role is to **support the AI safety community in Oxford**. You can find
out more about our mission [here](about).

If you're an AI safety researcher visiting Oxford, reach out to us
[here](mailto:gracie@oaisi.org). If you're based in Oxford and want to
reach out, email us [here](mailto:gracie@oaisi.org).

To get regular updates on what we're doing, sign up to our
[mailing list](http://eepurl.com/i1scNU).

Go to our [get in touch](getintouch) page to book 1-1 sessions with our
committee to chat about AI safety, OAISI, and how you can get involved.

<hr/>
Currently running:
[**OAISI AI Safety Fellowship**](aisafetyfellowship): Following a **3-3 structure**, our fellows will explore the fundamentals of AI safety for the first three weeks before specialising through either our **technical** or **governance track** for the later three weeks! Apply by January 22nd!

[**Technical Agendas Reading Group**](technicalagendas): This group will meet weekly to read and discuss key papers in a variety of technical AI safety research agendas. The exact agendas we choose to read will be decided based on the shared interests of the group.

[**Projects**](projects): work on an AI safety project in a group environment (pizza and project ideas provided!) every Thursday 7-10pm during term.

<hr/>

Previous:

- Our ML safety bootcamp, ([ARBOx](arbox)), began on the 6th - our participants are currently working hard and we're really excited about the progress they're making!
- A series of [**introductory talks**](introtalks) with _Orshi Dobe_, _Suryansh Mehta_, and _Michael Aird_ at the beginning of October
- We ran our new [**Strategy Fellowship**](strategy) last term with an original curriculum. In HT25 this has been turned into the [**OAISI AI Safety Fellowship**](aisafetyfellowship)
