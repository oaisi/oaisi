---
layout: ../layouts/Layout.astro
---

<div class='calloutbox'>
Currently running:

[**OAISI AI Safety Fellowship**](aisafetyfellowship): Following a **3-3 structure**, our fellows will explore the fundamentals of AI safety for the first three weeks before specialising through either our **technical** or **governance track** for the later three weeks! Apply by January 22nd!

[**Technical Agendas Reading Group**](technicalagendas): This group will meet weekly to read and discuss key papers in a variety of technical AI safety research agendas. The exact agendas we choose to read will be decided based on the shared interests of the group.

[**Projects**](projects): work on an AI safety project in a group environment (pizza and project ideas provided!) every Thursday 7-10pm during term.

</div>

**Catastrophic risk from advanced artificial intelligence may be the defining
issue of our time.**

OAISI's role is to **support the AI safety community in Oxford**. You can find
out more about our mission [here](about).

If you're an AI safety researcher visiting Oxford, reach out to us
[here](mailto:gracie@oaisi.org). If you're based in Oxford and want to
reach out, email us [here](mailto:gracie@oaisi.org).

To get regular updates on what we're doing, sign up to our
[mailing list](http://eepurl.com/i1scNU).

Go to our [get in touch](getintouch) page to book 1-1 sessions with our
committee to chat about AI safety, OAISI, and how you can get involved.

<hr/>

Previous:

- [**ARBOx**](arbox) is our ML safety bootcamp, which ran from 6-17th January
- A series of [**introductory talks**](introtalks) with _Orshi Dobe_, _Suryansh Mehta_, and _Michael Aird_ at the beginning of October
- Our [**Strategy Fellowship**](strategy) ran in Michaelmas, where participant grew their understanding of AIS metastrategy.
